<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CMDS</title>
    <url>/2025/02/27/CMDS/</url>
    <content><![CDATA[<h2 id="INTRO"><a href="#INTRO" class="headerlink" title="INTRO"></a>INTRO</h2><p>ZigZag, Timeloop, Maestro等著名的工作在优化DNN的数据流时将每一层的都看作是一个独立部分，没有考虑到层切换时不同数据流造成的影响，特别是不同数据流对内存使用方式的影响，这可能造成内存读写时的能量浪费。本文提出了一种跨层内存感知数据流调度器，考虑了不同层的内存布局需求对时延和功耗的影响，相比于现有工作能够得到能效更好的数据流安排方案。</p>
<h2 id="METHOD"><a href="#METHOD" class="headerlink" title="METHOD"></a>METHOD</h2><h3 id="multi-bank-memory-arch"><a href="#multi-bank-memory-arch" class="headerlink" title="multi-bank memory arch"></a>multi-bank memory arch</h3><img src="https://s21.ax1x.com/2025/02/27/pE3cQdU.png" title="" alt="" data-align="center">

<p>BD：bank的位宽</p>
<p>PD：外部对mem的读写位宽</p>
<p>MD：整个mem的物理位宽 &#x3D; BankNum * BD</p>
<img src="https://s21.ax1x.com/2025/02/27/pE30F3V.png" title="" alt="" data-align="center">

<p>上图展示了内存布局对不同数据流产生的影响：</p>
<p>BD:</p>
<p>Case1中Conv1层的输出，每4个同OX的数据存储到1个Bank的同一行，当Conv2需要每个周期消耗4个相同OY的数据时，每次读Bank都只有25%的有效数据。这会导致PE获取的数据不足，增加延迟 ；访问mem的总功耗增加。</p>
<p>Case2中Conv1按OY存储就可以保证两层的memory layout兼容。</p>
<p>PD：</p>
<p>multi-bank 的组合支持不同的WPD和RPD。例如case2中数据按OY &#x3D; 4的方式存储在Bank中，其他OX可以存储在不同bank的相同行，也可以存储在同一bank的不同行，这取决于Conv2采用的数据流。可用的PD选择必须包含可用的BD。</p>
<p>MD:</p>
<p>Case2采用了OX&#x3D;2 ，K&#x3D;2的内存布局，充分利用了MD的宽度同时支持特定的WPD和RPD。</p>
<h3 id="EXPERIMENT"><a href="#EXPERIMENT" class="headerlink" title="EXPERIMENT"></a>EXPERIMENT</h3><p>对比对象：无灵活数据接口的ACC &amp; 具有重排序缓冲区的ACC</p>
<h4 id="有效PD"><a href="#有效PD" class="headerlink" title="有效PD"></a>有效PD</h4><p>PD资源利用率不足有两种可能：</p>
<ol>
<li><p>给定数据流与BD数据布局不匹配</p>
</li>
<li><p>给定数据流与MD布局不匹配导致一次只能同时访问较少的Bank</p>
</li>
</ol>
<p>总之就是PE所需的数据和内存中的数据布局导致PD的利用不充分，进而导致能量和功耗损失。为了评估这一功耗损失，文章提出了计算“有效PD”的方法：</p>
<img title="" src="https://s21.ax1x.com/2025/02/27/pE3b4Rx.png" alt="" data-align="center">

<p>将有效PD带入CMDS即可更加实际的评估内存布局带来的影响。</p>
<h4 id="Reshuffling-buffer-cost"><a href="#Reshuffling-buffer-cost" class="headerlink" title="Reshuffling buffer cost"></a>Reshuffling buffer cost</h4><p>重新排序缓冲区放置在内存和PE之间，所需的寄存器数量为按照第 j 层 SU 的 RPD 数据布局重组数据而必须缓冲的第 i 层最终输出的数量。在不采取内存感知数据流的情况下，可以避免低效的内存访问，但有面积开销。</p>
<h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><p>将（1）ZigZag框架+含有Reshuffling buffer的架构和（2）ZigZag框架+普通mem架构与（3）CMDS框架+普通mem架构进行对比，可以发现（3）在使得总能耗和延迟仅有2-4%增加的情况下可以比（1）减小3-11%的面积开销，比（2）减少10-500%的能量延迟开销。</p>
<p>通过实验，本文还发现采用BD&lt;PD&lt;MD，且MD较大的参数会取得较好的效果。</p>
<p>存储器组的数量、CMDS 的灵活性和实现存储器组所需的面积之间存在权衡。</p>
]]></content>
      <categories>
        <category>gallery</category>
      </categories>
      <tags>
        <tag>Paper Notes</tag>
      </tags>
  </entry>
  <entry>
    <title>Git使用教程</title>
    <url>/2024/11/12/Git%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h3 id="1-Git-使用教程"><a href="#1-Git-使用教程" class="headerlink" title="1. Git 使用教程"></a>1. Git 使用教程</h3><h4 id="1-1-创建与提交"><a href="#1-1-创建与提交" class="headerlink" title="1.1 创建与提交"></a>1.1 创建与提交</h4><ol>
<li>在本地创建ssh key：</li>
</ol>
<p><code>ssh-keygen -t rsa -C &quot;your_email@youremail.com&quot;</code></p>
<ol start="2">
<li><p>输入上述命令后~&#x2F;.ssh中将出现一个id_rsd.pub文件，将该文件中的key复制到github的ssh key配置页面：</p>
<img src="https://s21.ax1x.com/2024/11/13/pAcz5uT.png" title="" alt="" data-align="center">
</li>
<li><p>输入<code> ssh -T git@github.com</code>确认是否key配置成功</p>
</li>
<li><p>配置信息：</p>
</li>
</ol>
<p><code>git config --global user.name &quot;your name&quot;  git config --global user.email &quot;your_email@youremail.com&quot;</code></p>
<ol start="5">
<li>在github上创建一个仓库，并在本地关联该仓库，此处有两种办法：</li>
</ol>
<p>① 直接将仓库clone到本地，进入仓库目录即可：</p>
<p><code>git clone git@github.com:JerryLiF/Chiplet_based_DSE_Simulator.git</code></p>
<p>② 建立一个与github上仓库同名的本地目录，进入该目录并输入<code>git init</code>初始化仓库。而后输入：<code>git remote add origin git@github.com:yourName/yourRepo.git</code>关联GitHub上的远端仓库。</p>
<p><mark>注意：旧版本git初始化后默认的分支为master，但新版本GithHub默认分支为main，为了保持一致需先将git升级到2.28版本之后，通过<code>git config --global init.defaultBranch main</code>命令进行全局修改。</mark></p>
<ol start="6">
<li><p>创建新文件或修改文件后，使用<code>git add *</code>命令将文件提交到暂存区</p>
</li>
<li><p>将改动提交到HEAD：<code>git commit -m &quot;备注&quot;</code></p>
</li>
<li><p>将改动提交到远程仓库：<code>git push origin 分支名称</code></p>
</li>
<li><p>分支操作：</p>
</li>
</ol>
<p>创建新分支：<code>git checkout -b feature_x</code></p>
<p>切换分支：<code>git checkout master</code></p>
<p>删除分支：<code>git branch -d feature_x</code></p>
<h4 id="1-2-更新与合并"><a href="#1-2-更新与合并" class="headerlink" title="1.2 更新与合并"></a>1.2 更新与合并</h4><p>将远端仓库的更新同步到本地：<code>git pull</code></p>
<p>合并其他分支到当前分支：<code>git merge &lt;branch&gt;</code></p>
<p>查看两个分支的差异：<code>git diff &lt;source_branch&gt; &lt;target_branch&gt;</code></p>
<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h3 id="2-GitHub使用"><a href="#2-GitHub使用" class="headerlink" title="2. GitHub使用"></a>2. GitHub使用</h3><h4 id="2-1-在vscode中向GitHub提交代码"><a href="#2-1-在vscode中向GitHub提交代码" class="headerlink" title="2.1 在vscode中向GitHub提交代码"></a>2.1 在vscode中向GitHub提交代码</h4><ol>
<li><p>使用vscode打开本地仓库的文件夹</p>
</li>
<li><p>进入源代码管理页面：</p>
</li>
</ol>
<p><img src="https://s21.ax1x.com/2024/11/13/pAczO81.png"></p>
<h3 id="3-基于Github和Hexo搭建个人博客"><a href="#3-基于Github和Hexo搭建个人博客" class="headerlink" title="3. 基于Github和Hexo搭建个人博客"></a>3. 基于Github和Hexo搭建个人博客</h3><p>常用命令：<br>    hexo new “postName” #新建文章<br>    hexo new page “pageName” #新建页面<br>    hexo generate #生成静态页面至public目录<br>    hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server）<br>    hexo deploy #部署到GitHub<br>    hexo help  # 查看帮助<br>    hexo version  #查看Hexo的版本</p>
]]></content>
      <tags>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>MOMM</title>
    <url>/2025/03/08/MOMM/</url>
    <content><![CDATA[<h2 id="INTRO"><a href="#INTRO" class="headerlink" title="INTRO"></a>INTRO</h2><p>NPU中的全局缓存通常组织为multi-bank的架构，本文针对减少片外访存和隐藏DRAM访问延迟的目标，提出了一种片上内存管理技术。</p>
<p>将权重缓存和输入输出缓存区分开来可以简化设计，权重缓存只需要使用double buffer设计就可以隐藏DRAM访问延迟；特征图像缓存则需要仔细的规划预取下一个输入段、读取当前输入段和写入输出段的顺序。</p>
<p>DRAM访问延迟的评估通过使用 Ramulator对 DRAM 仿真结果进行回归得到。</p>
<img src="https://s21.ax1x.com/2025/03/09/pEN9Mm4.png" title="" alt="" data-align="center">

<h2 id="MOMM"><a href="#MOMM" class="headerlink" title="MOMM"></a>MOMM</h2><p>MOMM的控制体系如图3所示：给出当前Bank状态和NN的信息，MOM manager 给出数据tile的映射方案、NPU处理顺序和新的Bank 状态。</p>
<img src="https://s21.ax1x.com/2025/03/09/pEN9uXF.png" title="" alt="" data-align="center">

<p>MOMM考虑不同的MEM Banks使用策略对DRAM访问量和DRAM访问延迟的影响（2个目标函数）：</p>
<h3 id="DRAM-first-Store"><a href="#DRAM-first-Store" class="headerlink" title="DRAM-first Store"></a>DRAM-first Store</h3><p>当片上缓存不足以存储整个输出特征图像时，优先将溢出的部分加载到DRAM中，减少存储OutFMAP的Bank数量。</p>
<p>如图4所示，使用简单的DRAM最低优先级方式会在步骤5时等待$ I_4$加载；使用DFS策略时，对DRAM来说输入读取和输出写入有访问竞争，如果下一次计算不访问预取数据，则可以延迟预取，不会降低性能。</p>
<img src="https://s21.ax1x.com/2025/03/09/pEN9l79.png" title="" alt="" data-align="center">

<h3 id="※DRAM-Access-Minimization-Policy"><a href="#※DRAM-Access-Minimization-Policy" class="headerlink" title="※DRAM Access Minimization Policy"></a>※DRAM Access Minimization Policy</h3><p>通过预设OFM可以占用的最大Bank数目决定Bank的使用顺序，如图5所示，当WMEM能够一次性缓存所有WGT时，a的DRAM访问次数更少，反之b更少。</p>
<img src="https://s21.ax1x.com/2025/03/09/pEN9n6U.png" title="" alt="" data-align="center">

<h3 id="MIN-Access-framework"><a href="#MIN-Access-framework" class="headerlink" title="MIN Access framework"></a>MIN Access framework</h3><p>确定使用的策略和存储OFM的bank数目→确定需要load input的bank数目→确定需要参与处理的banks数目→更新bank状态</p>
<img src="https://s21.ax1x.com/2025/03/09/pENPCIs.png" title="" alt="" data-align="center">

<h3 id="※DRAM-Access-Hiding-Policy"><a href="#※DRAM-Access-Hiding-Policy" class="headerlink" title="※DRAM Access Hiding Policy"></a>※DRAM Access Hiding Policy</h3><p>HIDE策略的目的是通过预取数据来隐藏DRAM的访问延迟，如果存在未加载的输入Tile，HIDE策略会在每一个控制步骤中至少保留一个可用的存储库用于预取。</p>
<p>MIN 策略处理所有可能的输入Tile，以最大限度地重复使用滤波器权值。HIDE 策略通过估算决策后的 PE 延迟来确定需要处理的输入瓦片数量。两者的对比如下图所示</p>
<img src="https://s21.ax1x.com/2025/03/09/pEN9mlT.png" title="" alt="图7" data-align="center">

<h3 id="Multi-path-NN"><a href="#Multi-path-NN" class="headerlink" title="Multi-path NN"></a>Multi-path NN</h3><img title="" src="https://s21.ax1x.com/2025/03/09/pEN9Vf0.png" alt="" data-align="center">

<p>面对具有多个分支的网络时，可能的方案选择非常复杂。假设 FMEM 库的数量为 N，网络并行路径的数量为B，那么可能的方案选择有$B!*(N-1)^{B-1}$种，$B!$是所有可能的处理顺序数，$（N-1）^{B-1}$是每条路径中可以留下输入Tile数目的总情况数。总情况数目非常庞大，本文提出了一种贪婪启发式来减少需要比较的案例数量，对于给定的路径排序，我们确定从第一条路径依次离开的输入Tile的数量，对所有选定的案例进行比较，以找到关于路径处理顺序和从每条路径离开的输入Tile数量的最佳决策。</p>
<h2 id="Hybrid-Fusion"><a href="#Hybrid-Fusion" class="headerlink" title="Hybrid Fusion"></a>Hybrid Fusion</h2><p>本文提出了一种介于完全融合和按顺序处理之间的混合融合方案，实质上就是需要在片上存储的图像大于FMEM但是比整张图像小。感觉这个点比较水。</p>
<img src="https://s21.ax1x.com/2025/03/09/pEN9epV.png" title="" alt="" data-align="center">
]]></content>
      <categories>
        <category>gallery</category>
      </categories>
      <tags>
        <tag>Paper Notes</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2024/09/02/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>ZigZag</title>
    <url>/2025/03/03/ZigZag/</url>
    <content><![CDATA[<p>loop blocking： 将某一维的for循环分配到特定的存储层级中</p>
<p>loop ordering： 在一个存储级别内交换for循环的排序</p>
<p>loop spatial unrolling： 将for循环空间并行展开</p>
]]></content>
      <categories>
        <category>gallery</category>
      </categories>
      <tags>
        <tag>Paper Notes</tag>
      </tags>
  </entry>
  <entry>
    <title>NoC of Xilinx ACAP</title>
    <url>/2024/11/13/NoC-of-Xilinx-ACAP/</url>
    <content><![CDATA[<h1 id="Network-on-Chip-Programmable-Platform-in-VersalTM-ACAP-Architecture"><a href="#Network-on-Chip-Programmable-Platform-in-VersalTM-ACAP-Architecture" class="headerlink" title="Network-on-Chip Programmable Platform in VersalTM ACAP Architecture"></a>Network-on-Chip Programmable Platform in VersalTM ACAP Architecture</h1><h2 id="1-INTRO"><a href="#1-INTRO" class="headerlink" title="1 INTRO"></a>1 INTRO</h2><p>在 FPGA上设计的电路日渐复杂，存储器带宽日渐增加和设计者更加关注面向需求的专用电路设计这三个因素共同推动着 FPGA 架构的演进。</p>
<p>随着制程提升，金属的线电阻不断增加，造成互连延迟增加，FPGA 布线时关键路径上的时延增加。</p>
<p>传统的 FPGA 互连面临两个问题，一是逻辑资源，二是设计的最高频率和关键路径时延无法被事先得知。<br>2 NoC</p>
<hr>
<ul>
<li>支持 QoS</li>
</ul>
<p>Quality of service is the ability to provide different priorities to different applications, users, or data <a href="https://en.wikipedia.org/wiki/Traffic_flow_(computer_networking)">flows</a>, or to guarantee a certain level of performance to a data flow.</p>
<ul>
<li>包含虚拟通道</li>
</ul>
<h2 id="3-Versal-NoC"><a href="#3-Versal-NoC" class="headerlink" title="3 Versal NoC"></a>3 Versal NoC</h2><p>Versal 架构</p>
<img title="arch" src="https://s21.ax1x.com/2024/11/13/pAcvzz6.png" alt="" data-align="center">

<p>NoC 在芯片中扮演两个角色：</p>
<ol>
<li>为芯片中所有资源提供永久的可统一寻址的互连</li>
<li>可以代替可编程逻辑提供开关和路由功能</li>
</ol>
<p>Versal NoC 数据包传输结构：AXI&#x2F;AXI-S</p>
<img title="" src="https://s21.ax1x.com/2024/11/13/pAcvvJ1.png" alt="loading-ag-351" data-align="center">

<p>Versal NoC 拓扑：</p>
<img title="" src="https://s21.ax1x.com/2024/11/13/pAcxpQK.png" alt="" data-align="center">

<p>Versal NoC 可以分为两部分：HNoC 和 VNoC</p>
<p>HNoC 水平分布，上下连接芯片中的硬核，VNoC 垂直分布，连接可编程结构。 VNoC 不是独立的互连结构，其像 DSP 一样作为一个硬核集成在可编程结构中。</p>
<p>Versal NoC 的一个重要作用是高效管理各模块对 DDR 的访问，VNoC 的频率和带宽与 DDR 相匹配：</p>
<p><code>&lt;mark&gt;</code>For example, a device with 64 bit DDR4 3200 has 25.6GBps bandwidth. A VNoC running at 1GHz has two physical channels supporting upto 16GBps each per direction.<code>&lt;/mark&gt;</code></p>
<p>NoC 支持可编程交织式的使用内存，将所有内存看做一个存储池，交织式的在每一个 DDR 上操作 128B 到 4KB 的空间。</p>
<p> Versal NoC 的路由表是可编程的（不同的设计用到的资源和连接不同），NoC 在多个 DIE 上是逻辑统一的。</p>
<h2 id="4-基于-Versal-NoC-的设计"><a href="#4-基于-Versal-NoC-的设计" class="headerlink" title="4 基于 Versal NoC 的设计"></a>4 基于 Versal NoC 的设计</h2><hr>
<p>与 SoC 中的 NoC 相比，Versal NoC 是可编程的，其拓扑，带宽和 QoS 都可以自定义，其允许所有可能的点对点通信。</p>
<h2 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a>5 结论</h2><hr>
<p>使用可编程逻辑实现 NoC 时，NoC 能够提供的带宽与计算节点的放置位置相关，而 NoC 硬核能够提供的带宽则不受位置影响。NoC 的编程和优化远快于可编程逻辑布局布线。</p>
<img title="" src="https://s21.ax1x.com/2024/11/13/pAcvxRx.png" alt="" data-align="center">
]]></content>
      <categories>
        <category>gallery</category>
      </categories>
      <tags>
        <tag>Paper Notes</tag>
      </tags>
  </entry>
</search>
